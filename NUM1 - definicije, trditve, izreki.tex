\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[slovene]{babel}

\usepackage{amsthm}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{relsize}
\usepackage{listings}
\lstset{
	basicstyle=\ttfamily,
	mathescape
}

\theoremstyle{definition}
\newtheorem{definicija}{Definicija}[section]

\newtheorem{lema}{Lema}
\newtheorem{trditev}{Trditev}
\newtheorem{izrek}{Izrek}
\newtheorem*{dokaz}{Dokaz}
\newtheorem*{algoritem}{Algoritem}
\newtheorem*{posledica}{Posledica}
\newtheorem*{opomba}{Opomba}
\newtheorem*{metoda}{Metoda}

\title{Numerične metode 1 - definicije, trditve in izreki}
\author{Oskar Vavtar \\
po predavanjih profesorja Bora Plestenjaka}
\date{2020/21}

\begin{document}
\maketitle
\pagebreak
\tableofcontents
\pagebreak

% #################################################################################################

\section{NUMERIČNO RAČUNANJE}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Uvod}
\vspace{0.5cm}

\begin{definicija}[Napaka]

Pri numeričnem računanju izračunamo numerični približek za točno rešitev. Razlika med približkom in točno vrednostjo je \textit{napaka} približka. Ločimo \textit{absolutno} in \textit{relativno} napako.

\begin{itemize}
	\item absolutna napaka $=$ približek $-$ točna vrednost
	\item relativna napaka $=$ $\frac{\text{absolutna napaka}}{\text{točna vrednost}}$
\end{itemize}

Naj bo $x$ točna vrednost, $\hat{x}$ pa približek za $x$.

\begin{itemize}
	\item Če je $\hat{x} = x + d_a$, potem je $d_a = \hat{x} - x$ \textit{absolutna napaka}.
	\item Če je $\hat{x} = x(1 + d_r)$, potem je $d_r = \frac{\hat{x} - x}{x}$ \textit{relativna napaka}.
\end{itemize}

\end{definicija}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Premična pika}
\vspace{0.5cm}

\begin{definicija}

Velja fl$(x) = x(1 + \delta)$ za $|\delta| \leq u$, kjer je
$$u ~=~ \frac{1}{2}b^{1-t}$$
\textit{osnovna zaokrožitvena napaka}:

\begin{itemize}
	\item single: $u = 2^{-24} = 6 \times 10^{-8}$
	\item double: $u = 2^{-53} = 1 \times 10^{-16}$
\end{itemize}

\end{definicija}
\vspace{0.5cm}

\begin{izrek}

Če za število $x$ velja, da $|x|$ leži na intervalu med najmanjšim in največjim \textit{pozitivnim predstavljivim normaliziranim} številom, potem velja
$$\frac{|\text{fl}(x) - x|}{|x|} ~\leq~ u.$$

\end{izrek}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Občutljivost problema}
\vspace{0.5cm}

\begin{definicija}[Občutljivost]

Če se rezultat pri majhni spremembi argumentov\footnote{\textit{Motnji} oz. \textit{perturbaciji}.} ne spremeni veliko, je problem \textit{neobčutljiv}, sicer pa je \textit{občutljiv}.

\end{definicija}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Vrste napak pri numeričnem računanju}
\vspace{0.5cm}

\begin{definicija}

Pri numeričnem računanje se pojavijo 3 vrste napak:
\begin{enumerate}
	\item \textsc{Neodstranljive napake}: 
	Npr. ko podatek ni predstavljivo število. Namesto $y = f(x)$ lahko v najboljšem primeru izračunamo $\overline{y} = f(\overline{x})$, kjer je $\overline{x}$ najbližje predstavljivo število. 
	$$D_n ~=~ y - \overline{y} ~=~ f(x) - f(\overline{x})$$
	\item \textsc{Napaka metode}:
	Npr. ko na voljo nimamo željene operacije. Namesto $f(\overline{x})$ potem izračunamo $\widetilde{y}=g(\overline{x})$, kjer je $g(x)$ približek za $f(x)$, kjer znamo vrednost $g$ izračunati s končnim številom operacij. 
	$$D_m ~=~ \overline{y} - \widetilde{y} ~=~ f(\overline{x}) - g(\overline{x})$$
	\item \textsc{Zaokrožitvene napake}:
	Pri izračunu $\widetilde{y}=g(\overline{x})$ lahko pri vsaki osnovni operaciji pride do zaokrožitvene napake, zato na koncu kot numeričen rezultat dobimo $\widehat{y}$.
	$$D_z ~=~ \widetilde{y} - \widehat{y}$$
\end{enumerate}

Skupna napaka:
$$D ~=~ D_n + D_m + D_z$$

V splošnem lahko ocenimo:
$$|D| ~\leq~ |D_n| + |D_m| + |D_z|$$
\end{definicija}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Stabilnost metode}
\vspace{0.5cm}

\begin{definicija}

Če metoda za $\forall x$ vrne $\widehat{y}$, ki je \textit{absolutno (relativno)} blizu točnemu $y$, je metoda \textit{direktno stabilna}.

Če metoda za $\forall x$ vrne tak $\widehat{y}$, da $\exists \widehat{x}$ absolutno (relativno) blizu $x$, da je $\widehat{y}=f(\widehat{x})$ (točno), je metoda \textit{obratno stabilna}. \\

\noindent V splošnem:
$$|\text{direktna napaka}| ~\leq~ |\text{občutljivost}| \cdot |\text{obratna napaka}|$$

\end{definicija}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Analiza zaokrožitvenih napak}
\vspace{0.5cm}

\subsubsection{Produkt $n+1$ predstavljivih števil}

\begin{algoritem}

Dana so predstavljiva števila $x_0, x_1, \ldots, x_n$; \\ računamo $p = x_0 \cdot x_1 \cdot \ldots \cdot x_n$. \\

\noindent \textsc{Točno}:
\begin{lstlisting}
p$_\texttt{0}$ = x$_\texttt{0}$
i = 1,...,n
$~~~~$p$_\texttt{i}$ = p$_\texttt{i-1} \cdot$x$_\texttt{i}$
p = p$_\texttt{n}$
\end{lstlisting} 

\noindent \textsc{Numerično}:
\begin{lstlisting}
$\widehat{\texttt{p}}_\texttt{0}$ = x$_\texttt{0}$
i = 1,...,n
$~~~~$$\widehat{\texttt{p}}_\texttt{i}$ = $\widehat{\texttt{p}}_\texttt{i-1} \cdot$x$_\texttt{i}\cdot$(1 + $\delta_\texttt{i}$)$~~|\delta_\texttt{i}| \leq$ u
$\widehat{\texttt{p}}$ = $\widehat{\texttt{p}}_\texttt{n}$
\end{lstlisting}

\end{algoritem}
\vspace{0.5cm}
\pagebreak

\subsubsection{Skalarni produkt vektorjev dolžine $n$}

\begin{algoritem}

Imamo vektorje \textit{predstavljivih} števil $a = [a_1, \dots, a_n]^T$, $b = [b_1, \dots, b_n]^T$. Računamo $s = \langle b^T, a \rangle = \mathlarger{\sum_{i=1}^n a_i b_i}$.

\noindent \textsc{Točno}:
\begin{lstlisting}
s$_\texttt{0}$ = 0
i = 1,...,n
$~~~~$p$_\texttt{i}$ = a$_\texttt{i} \cdot$b$_\texttt{i}$
$~~~~$s$_\texttt{i}$ = s$_\texttt{i-1}$ + p$_\texttt{i}$
s = s$_\texttt{n}$
\end{lstlisting}

\noindent \textsc{Numerično}:
\begin{lstlisting}
$\widehat{\texttt{s}}_\texttt{0}$ = 0
i = 1,...,n
$~~~~\widehat{\texttt{p}}_\texttt{i}$ = a$_\texttt{i} \cdot$b$_\texttt{i} \cdot$(1 + $\alpha_i$)$~~~~~~~~|\alpha_i| \leq u$
$~~~~\widehat{\texttt{s}}_\texttt{i}$ = ($\widehat{\texttt{s}}_\texttt{i-1}$ + $\widehat{\texttt{p}}_\texttt{i}$)$\cdot$(1 + $\beta_i$)$~~|\beta_i| \leq u$
$\widehat{\texttt{s}}$ = $\widehat{\texttt{s}}_\texttt{n}$
\end{lstlisting}

\end{algoritem}
\vspace{0.5cm}

\begin{trditev}

Računanje skalarnega produkta je \textit{obratno} stabilno, ni pa \textit{direktno} stabilno.

\end{trditev}
\vspace{0.5cm}

% *************************************************************************************************

\pagebreak

% #################################################################################################

\section{NELINEARNE ENAČBE}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Uvod}
\vspace{0.5cm}

\begin{definicija}

Naj bo $\alpha$ ničla funkcije $f$, ki je \textit{zvezno odvedljiva} v okolici $\alpha$:
\begin{itemize}

	\item $f'(\alpha) \neq 0$: $\alpha$ je \textit{enostavna} ničla
	
	\item $f'(\alpha) = 0$: $\alpha$ je \textit{večkratna} ničla \\
	
	Če je $f$ $m$-krat zvezno odveljiva in
	$$f'(\alpha) ~=~ f''(\alpha) ~=~ \ldots ~=~ f^{(m-1)}(\alpha) ~=~ 0,~~f^{(m)} \neq 0,$$
	je $\alpha$ $m$-kratna ničla.

\end{itemize}

\end{definicija}
\vspace{0.5cm}

\begin{trditev}[Občutljivost ničel]

Naj bo $\alpha$ enostavna ničla. Če v okolici $x = \alpha$ obstaja inverzna funkcija $\alpha = f^{-1}(0)$ v bistvu "računamo" vrednost inverzne funkcije. Občutljivost je enaka absolutni vrednosti odvoda inverzna funkcije:
$$|(f^{-1})'(0)| ~=~ \frac{1}{|f'(f^{-1}(0))|} ~=~ \frac{1}{|f'(\alpha)|}.$$

Večkratno ničlo lahko izračunamo le z natančnostjo $u^{\frac{1}{m}}$, kjer je $m$ večkratnost ničle (za dvojno ničlo dobimo le polovico točnih decimalk, za trojno le tretjino...). 

\end{trditev}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Bisekcija}
\vspace{0.5cm}

\begin{izrek}

Če je $f$ realna zvezna funkcija na $[a, b]$ in je $f(a) \cdot f(b) < 0$, potem $\exists \xi \in (a, b)$, da je $f(\xi) = 0$.

\end{izrek}
\vspace{3cm}

\begin{algoritem}[Bisekcija]

Naj velja $f(a) \cdot f(b) < 0$ in $a < b$:
\begin{lstlisting}
e = b - a
while e > $\varepsilon$
$~~~~$e = e/2, c = a + e
$~~~~$if sign(f(c)) = sign(f(a))
$~~~~~~~~$a = c
$~~~~$else
$~~~~~~~~$b = c
\end{lstlisting}
\end{algoritem}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Navadna iteracija}
\vspace{0.5cm}

\begin{algoritem}[Navadna iteracija]
~\\
\begin{lstlisting}
izberi x$_\texttt{0}$
r = 0, 1, 2,...
$~~~~$x$_{\texttt{r+1}}$ = g(x$_{\texttt{r}}$)
\end{lstlisting}
~\\
Ustavitveni kriterij:
\begin{enumerate}
	\item[a)] $r > r_{max}$ (prekoračeno število korakov)
	\item[b)] $|r_{x+1} - r_x| < \varepsilon$
\end{enumerate}
\end{algoritem}
\vspace{0.5cm}

\begin{izrek}

Naj bo $\alpha = g(\alpha)$ in naj iteracijska  funkcija $g$ na intervalu $I = [\alpha - \delta, \alpha + \delta]$ za nek $\delta > 0$ zadošča Lipschitzovem pogoju
$$|g(x) - g(y)| ~\leq~ m|x - y| ~~\text{za}~~ x, y \in I, ~0 \leq m < 1.$$
Potem za $\forall x_0 \in I$ zaporedje $x_{r+1} = g(x_r)$, $r = 0, 1, \ldots$ konvergira k $\alpha$ in velja
\begin{itemize}
	\item $|x_r - \alpha| ~\leq~ m^r \cdot |x_0 - \alpha|$
	\item $|x_{r+1} - \alpha| ~\leq~ \cfrac{m}{1-m} \cdot |x_{r+1} - x_r|$
\end{itemize}

\end{izrek}
\vspace{0.5cm}

\begin{posledica}

Naj bo $\alpha = g(\alpha)$, $g$ \textit{zvezno odvedljiva} in $|g'(\alpha)| < 1$. Potem $\exists \delta > 0$, da za $\forall x_0 \in [\alpha - \delta, \alpha + \delta]$ zaporedje $x_{r+1} = g(x_r)$ konvergira k $\alpha$.

\end{posledica}
\vspace{0.5cm}

\begin{definicija}

Naj zaporedje $\{ x_r \}$ konvergira proti $\alpha$ \footnote{$\mathlarger{\lim_{r \rightarrow \infty}} x_r = \alpha$}. Pravimo, da zaporedje konvergira z redom konvergence $p$, če obstaja limita
$$\lim_{r \rightarrow \infty} \frac{|x_{r+1} - \alpha|}{|x_r - \alpha|^p} ~=~ C > 0.$$

\end{definicija}
\vspace{0.5cm}

\begin{izrek}

Naj bo iteracijska funkcija $g$ $p$-krat \textit{zvezno odvedljiva} v okolici negibne točke $\alpha$. Če velja $g'(\alpha) = \ldots = g^{(p-1)}(\alpha) = 0$ in $g^{(p)}(\alpha) \neq 0$, potem zaporedje $x_{r+1} = g(x_r)$, $r = 0, 1, \ldots$, v okolici $\alpha$ konvergira z redom $p$. V primeru $p = 1$ mora za konvergenco veljati še $|g'(\alpha)| < 1$. 

\end{izrek}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Tangentna metoda}
\vspace{0.5cm}

\begin{metoda}

$$x_{r+1} ~=~ x_r - \frac{f(x_r)}{f'(x_r)}$$
Konvergenca:
$$|e_{r+1}| ~\approx~ C \cdot |e_r|^2$$

\end{metoda}
\vspace{0.5cm}

\begin{posledica}

Če je $f$ \textit{dvakrat zvezno odvedljiva} v okolici ničle $\alpha$, potem tangentna metoda za dovolj dober začetni približek $x_0$ vedno konvergira k $\alpha$.

\end{posledica}
\vspace{0.5cm}

\begin{izrek}

Naj bo funkcija $f$ na $I = [a, \infty)$ \textit{dvakrat zvezno odvedljiva, naraščajoča in ima ničlo na $\alpha \in I$}. Potem je $\alpha$ edina ničla na $I$ in za $\forall x_0 \in I$ tangentna metoda konvergira le k $\alpha$.

\end{izrek}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Metode brez $f'$}
\vspace{0.5cm}


\begin{metoda}[Sekantna metoda]

$$x_{r+1} ~=~ x_r - \frac{f(x_r)(x_r - x_{r-1})}{f(x_r) - f(x_{r-1})}$$
Konvergenca:
$$|e_{r+1}| ~\approx~ C \cdot |e_r| \cdot |e_{r-1}|$$

\end{metoda}
\vspace{0.5cm}

\begin{metoda}[Mullerjeva metoda]

Skozi točke $(x_r, f(x_r))$, $(x_{r-1}, f(x_{r-1}))$, \\$(x_{r-2}, f(x_{r-2}))$ potegnemo kvadratni polinom $y = p(x)$ in za $x_{r+1}$ vzamemo tisto ničlo polinoma $p$, ki je bližje $x_r$. \\

\noindent Konvergenca:
$$|e_{r+1}| ~\approx~ C \cdot |e_r| \cdot |e_{r-1}| \cdot |e_{r-2}|$$

\end{metoda}
\vspace{0.5cm}

\begin{metoda}[Inverzna interpolacija]

Zamenjamo vlogi $x$ in $y$ in vzamemo kvadratni polinom $x = \mathcal{L}(y)$, ki gre skozi točke $(f(x_r), x_r)$, $(f(x_{r-1}), x_{r-1})$, $(f(x_{r-2}), x_{r-2})$. Za $x_{r+1}$ vzamemo
$$x_{r+1} ~=~ \mathcal{L}(0).$$
Red konvergence je enak kot pri \textit{Mullerjevi metodi}.

\end{metoda}
\vspace{0.5cm}

% *************************************************************************************************

\pagebreak

% #################################################################################################

\section{SISTEMI LINEARNIH ENAČB}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Oznake in definicije}
\vspace{0.5cm}

\begin{definicija}

Sistem $n$ linearnih enačb z $n$ neznankami pišemo v obliki
$$Ax ~=~ b, ~~A \in \mathbb{R}^{n \times n} ~(\mathbb{C}^{n \times n}), ~x, b \in \mathbb{R}^n ~(\mathbb{C}^n).$$

\end{definicija}
\vspace{0.5cm}

\begin{definicija}

Skalarni produkt vektorjev $x$ in $y$ je enaka
\begin{enumerate}
	\item[a)] $x, y \in \mathbb{R}^n$:
	$$y^T x ~=~ \sum_{i=1}^n x_i y_i ~=~ \langle x, y \rangle ~=~ \langle y, x \rangle$$
	\item[b)] $x, y \in \mathbb{C}^n$:
	$$y^H x ~=~ \sum_{i=1}^n x_i \overline{y_i} ~=~ \langle x, y, \rangle ~=~ \overline{\langle y, x \rangle}$$
\end{enumerate}

\end{definicija}
\vspace{0.5cm}

\begin{definicija}

Množenje vektorja $x$ z matriko $A$:
\begin{enumerate}
	\item[a)] $$y_i ~=~ \sum_{k=1}^n a_{ik} x_k ~=~ \alpha_i^T x$$
	\item[b)] $$y ~=~ \sum_{i=1}^n x_i a_i$$
\end{enumerate}

\end{definicija}
\vspace{0.5cm}

\pagebreak

\begin{definicija}

$A \in \mathbb{R}^{n \times n}$ je \textit{nesingularna}, če (ekvivalentno):
\begin{enumerate}
	\item[a)] $\det{(A)} \neq 0$
	\item[b)] obstaja inverz $A^{-1}$, da je $A^{-1}A = AA^{-1} = I$
	\item[c)] $rang{(A)} = n$
	\item[d)] za $\forall x \neq 0$ je $Ax \neq 0$
	\item[e)] $\ker{(A)} = \{x ~|~ Ax = 0\} = \{0\}$
\end{enumerate}

\end{definicija}
\vspace{0.5cm}

\begin{definicija}

Matrika je \textit{simetrično pozitivno definitna}, če $A = A^T$ in $x^T A x > 0$ za $x \neq 0$.

\end{definicija}
\vspace{0.5cm}

\begin{definicija}

Če za $x \neq 0$ velja $Ax = \lambda x$, je $\lambda$ lastna vrednost in $x$ lastni vektor. Vsaka matrika ima $n$ lastnih vrednosti, ki so ničle karakterističnega polinoma
$$p(\lambda) ~:=~ \det{(A - \lambda I)}.$$

\end{definicija}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Vektorske in matrične norme}
\vspace{0.5cm}

\begin{definicija}

Vektorska norma je preslikava $\|.\|: \mathbb{C}^n \rightarrow \mathbb{R}$, da velja:
\begin{enumerate}
	\item[1)] Nenegativnost: 
	$$\|x\| ~\geq~ 0, ~~~\|x\| = 0 \iff x = 0$$
	\item[2)] Homogenost:
	$$\|\alpha x\| ~=~ |\alpha| \cdot \|x\|$$
	\item[3)] Trikotniška neenakost:
	$$\|x+y\| ~\leq~ \|x\| + \|y\|$$
\end{enumerate}

\end{definicija}
\vspace{0.5cm}

\pagebreak

\begin{definicija}

Matrična norma je preslikava $\|.\|: \mathbb{C}^{n \times n} \rightarrow \mathbb{R}$, da velja:
\begin{enumerate}
	\item[1)] Nenegativnost:
	$$\|A\| ~\geq~ 0, ~~~\|A\| = 0 \iff A = 0$$
	\item[2)]Homogenost:
	 $$\|\alpha A\| ~=~ |\alpha| \cdot \|A\|$$
	\item[3)] Trikotniška neenakost
	$$\|A + B\| ~\leq~ \|A\| + \|B\|$$
	\item[4)] Submultiplikativnost:
	$$\|A \cdot B\| ~\leq~ \|A\| \cdot \|B\|$$
\end{enumerate}
za $\forall A, B \in \mathbb{C}^{n \times n}$ in $\forall \alpha \in \mathbb{C}$.

\end{definicija}
\vspace{0.5cm}

\begin{lema}[Operatorska norma]

Če je za poljubno vektorsko normo $\|.\|_v$ definiramo 
$$\|A\| ~:=~ \max_{x \neq 0} \frac{\|Ax\|_v}{\|x\|_v},$$
je to matrična norma.

\end{lema}
\vspace{0.5cm}

\begin{lema}

$$\|A\|_1 ~=~ \max_{j = 1, \ldots, n} \|a_j\|_1 ~=~ \max_{j = 1, \ldots, n} \sum_{i=1}^n |a_{ij}|$$

\end{lema}
\vspace{0.5cm}

\begin{lema}[Spektralna norma]

$$\|A\|_2 ~=~ \sigma_1 (A) = \max_{i = 1, \ldots, n} \sqrt{\lambda_i (A^H A)}$$

\end{lema}
\vspace{0.5cm}

\begin{lema}

Za vsako matrično normo $\|.\|_m$ obstaja taka vektorska norma $\|.\|_v$, ki je z njo usklajena, kar pomeni, da za vse pare $A, x$ velja
$$\|A x\|_v ~\leq~ \|A\|_m \cdot \|x\|_v.$$

\end{lema}
\vspace{0.5cm}

\begin{lema}

Za vsako lastno vrednost $\lambda$ in poljubno matrično normo $\|A\|$ velja:
$$|\lambda| ~\leq~ \|A\|.$$

\end{lema} 
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Občutljivost sistemov linearnih enačb}
\vspace{0.5cm}

\begin{lema}

Če je $\|X\| < 1$, potem velja:
\begin{enumerate}
	\item[a)] $I-X$ je \textit{nesingularna}
	\item[b)] $(I-X)^{-1} ~=~ \mathlarger{\sum_{i=0}^{\infty} X ^i} ~=~ I + X + X^2 + \ldots$
	\item[c)] Če je $\|I\| = 1$, ~je $\|(I-X)^{-1}\| ~\leq~ \cfrac{1}{1-\|X\|}$
\end{enumerate}

\end{lema}
\vspace{0.5cm}

\begin{izrek}

Naj bo $A$ \textit{nesingularna} in $\Delta A$ taka motnja, da je $\|\Delta A\| < \frac{1}{\|A^{-1}\|}.$
Če je $Ax = b$ in $(A + \Delta A)(x + \Delta x) = b + \Delta b$, potem velja:
$$\frac{\|\Delta x\|}{\|x\|} ~\leq~ \frac{K(A)}{1 - K(A)\frac{\|\Delta A\|}{\|A\|}} \left( \frac{\|\Delta A\|}{\|A\|} + \frac{\|\Delta b\|}{\|b\|} \right),$$
kjer je $K(A) = \|A\| \cdot \|A^{-1}\|$.

\end{izrek}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{LU razcep}
\vspace{0.5cm}

\begin{izrek}

Za matriko $A$ je ekvivalentno:
\begin{enumerate}
	\item[1)] Obstaja enoličen razcep $A = LU$
	\item[2)] Vse vodilne podmatrike $A_k = A(1:k, 1:k)$ so nesingularne
\end{enumerate}

\end{izrek}
\vspace{0.5cm}

\pagebreak

\begin{algoritem}[LU razcep]
~
\begin{lstlisting}
j = 1,...,n-1
$~~~~$i = j+1,...,n
$~~~~~~~~$l$_{\texttt{ij}}$ = $\cfrac{\texttt{a}_{\texttt{ij}}}{\texttt{a}_{\texttt{jj}}}$
$~~~~~~~~$k = j+1,...,n
$~~~~~~~~~~~~$a$_{\texttt{ik}}$ = a$_{\texttt{ik}}$ - l$_{\texttt{ij}}$a$_{\texttt{jk}}$
\end{lstlisting}
Zahtevnost algoritma je odvisna od števila operacij. Preštejmo osnovne računske operacije:
$$\sum_{j=1}^{n-1} \left( \sum_{i=j+1}^n \left( 1 + \sum_{k=j+1}^n 2 \right) \right) ~=~ \frac{(n-1)n}{2} + 2 \frac{(n-1)n(2n-1)}{6} ~=~ \frac{2}{3}n^3 + \sigma(n^2)$$

\end{algoritem}
\vspace{0.5cm}

\begin{algoritem}[Prema substitucija]
~\\
Sistem $Ly = b$ rešujemo s premo substitucijo:
\begin{lstlisting}
i = 1,...,n
$~~~~$y$_{\texttt{i}}$ = b$_{\texttt{i}}$ - $\mathlarger{\sum_{\texttt{j=1}}^{\texttt{i-1}} \texttt{l}_{\texttt{ij}} \texttt{y}_{\texttt{j}}}$
\end{lstlisting}
Število operacij:
$$\sum_{i=1}^n (1 + 2(i-1)) ~=~ n + 2\frac{(n-1)n}{2} ~=~ n^2$$

\end{algoritem}
\vspace{0.5cm}

\begin{algoritem}
~
\begin{lstlisting}
i = n,n-1,...,1
$~~~~$x$_{\texttt{i}}$ = $\cfrac{\texttt{1}}{\texttt{u}_\texttt{ii}}$(y$_{\texttt{i}}$ - $\mathlarger{\sum_{\texttt{j=i+1}}^{\texttt{n}} \texttt{u}_{\texttt{ij}} \texttt{x}_{\texttt{j}}}$)
\end{lstlisting}
Število opracij:
$$n^2 + n$$

\pagebreak

\end{algoritem}
\vspace{0.5cm}

\begin{algoritem}[LU razcep z delnim pivotiranjem]
~
\begin{lstlisting}
j = 1,...,n-1
$~~~~$poisci |a$_{\texttt{p}_\texttt{j}}$| = max$_{\texttt{j} \leq \texttt{l} \leq \texttt{n}}$ |a$_{\texttt{l}_\texttt{j}}$|
$~~~~$zamenjaj vrstici j in p
$~~~~$i = j+1,...,n
$~~~~~~~~$l$_{\texttt{ij}}$ = $\cfrac{\texttt{a}_{\texttt{ij}}}{\texttt{a}_{\texttt{jj}}}$
$~~~~~~~~$k = j+1,...,n
$~~~~~~~~~~~~$a$_{\texttt{ik}}$ = a$_{\texttt{ik}}$ - l$_{\texttt{ij}}$a$_{\texttt{jk}}$
\end{lstlisting}
Pri pivotiranju vedno velja $|l_{ij}| \leq 1$, saj saj je $|a_{ij}| \leq |a_{jj}|$ 

\end{algoritem}
\vspace{0.5cm}

\begin{izrek}

Če je $\det{(A)} \neq 0$, potem obstaja taka permutacijska matrika $P$, da obstaja LU razcep 
$$PA ~=~ LU,$$
kjer je $L$ spodnjetrikotniška matrika, $U$ pa zgornjetrikotniška matrika.

\end{izrek}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Stabilnost reševanja sistemov in LU razcepov}
\vspace{0.5cm}

\begin{lema}

Naj bo $L$ \textit{nesingularna spodnje trikotna} matrika velikosti $n \times n$. Če sistem $Ly = b$ rešimo s premo substitucijo, potem izračunani $\hat{y}$ zadošča
$$(L + \Delta L) \hat{y} ~=~ b,$$
kjer je $|\Delta L| \leq n u |L|$. Reševanje spodenje trikotnega sistema s premo substitucijo je torej obratno stabilno.

\end{lema}
\vspace{0.5cm}

\begin{lema}

Naj bo $U$ \textit{zgornje trikotna} matrika velikosti $n \times n$, $\det{U} \neq 0$. Če sistem $Ux = y$ rešimo z obratno substitucijo, potem numerično izračunani $\hat{x}$ zadošča
$$(U + \Delta U) \hat{x} ~=~ y,$$
kjer je 
$$|\Delta U| ~\leq~ n u |U|.$$ 
Reševanje z obratno substitucijo je tudi obratno stabilno.

\end{lema}
\vspace{0.5cm}

\begin{lema}

Naj bo $A$ \textit{nesingularna} matrika velikosti $n \times n$, kjer se izvede LU razcep brez pivotiranja. Za izračunani matriki $\hat{L}$ in $\hat{U}$ velja
$$A + E ~=~ \hat{L} \hat{U},$$
kjer je 
$$|E| ~\leq~ n u |\hat{L}| |\hat{U}|.$$

\end{lema}
\vspace{0.5cm}

\begin{izrek}

Za izračunano rešitev $\hat{x}$ sistema linearnih enačb $Ax = b$ z uporabo LU razcepa velja 
$$(A + \Delta A) \hat{x} ~=~ b,$$
kjer je 
$$|\Delta A| ~\leq~ 3 n u |L| |U| + \sigma(u^2).$$

\end{izrek}
\vspace{0.5cm}

% *************************************************************************************************

\pagebreak

% #################################################################################################

\section{SISTEMI NELINEARNIH ENAČB}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Uvod}
\vspace{0.5cm}

\begin{definicija}

Sistem nelinearnih enačb je sistem oblike
\begin{align*}
f_1(x_1, \ldots, x_n) ~&=~ 0 \\
\vdots \\
f_n(x_1, \ldots, x_n) ~&=~ 0
\end{align*}
za $f_i: \mathbb{R}^n \rightarrow \mathbb{R}$. Krajše zapišemo kot
$$F(x) ~=~ 0, ~~~F = \begin{bmatrix}
f_1 \\
\vdots \\
f_n
\end{bmatrix},$$
kjer je $F: \mathbb{R}^n \rightarrow \mathbb{R}^n$ in $x \in \mathbb{R}^n$.

\end{definicija}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Navadna iteracija}
\vspace{0.5cm}

\begin{metoda}

To je posplošitev navadne iteracije za eno spremenljivko. Poiščemo funkcijo $G: \mathbb{R}^n \rightarrow \mathbb{R}^n$, da velja
$$F(\alpha) = 0 ~\iff~ \alpha = G(\alpha), ~~~\alpha \in \mathbb{R}^n.$$
Izberemo $x^{(0)} \in \mathbb{R}^n$ in tvorimo zaporedje
$$x^{(r+1)} ~=~ G(x^{(r)}), ~~~r = 0, 1, \ldots$$

\end{metoda}
\vspace{0.5cm}

\begin{izrek}

Naj bo bo $G: \mathbb{R}^n \rightarrow \mathbb{R}^n$ zvezno odvedljiva na $\Omega \subset \mathbb{R}^n$. Če velja:
\begin{enumerate}
	\item[a)] $x \in \Omega ~\Rightarrow~ G(x) \in \Omega$
	\item[b)] $x \in \Omega ~\Rightarrow~ \rho(JG(x)) \leq m < 1$
\end{enumerate}
potem ima $G$ v $\Omega$ natanko eno negibno točko $\alpha$ in zaporedje $x^{(r+1)} = G(x^{(r)})$, $r = 0, 1, \ldots$, za $\forall x^{(0)} \in \Omega$ konvergira k $\alpha$. Tu je
$JG(x) ~=~ \begin{bmatrix}
\frac{\partial g_1}{\partial x_1}(x) & \ldots & \frac{\partial g_1}{\partial x_n}(x) \\
\vdots & \ddots & \vdots \\
\frac{\partial g_n}{\partial x_1}(x) & \ldots & \frac{\partial g_n}{\partial x_n}(x)
\end{bmatrix}$
Jacobijeva matrika parcialnih odvodov in $\rho$ spektralni radij\footnote{Največja absolutna vrednost lastnih vrednosti.}.

\end{izrek}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Newtonova metoda}
\vspace{0.5cm}

\begin{metoda}

Naj bo $x$ približek za ničlo funkcije $f$. Iščemo popravek $\Delta x$, da bo $F(x + \Delta x) = 0$. Z uporabo razvoja v Taylorjevo vrsto dobimo
$$F(x + \Delta x) ~=~ F(x) + JF(x) \cdot \Delta x + \underbrace{\mathcal{O}(\|\Delta x\| ^2)}_{\text{zanemarimo}}.$$
Iz tega sledi $\Delta x = -JF(x)^{-1} \cdot F(x)$, za nov približek vzamemo torej
$$x + \Delta x ~=~ x - JF(x)^{-1} \cdot F(x),$$
za iteracijsko funkcijo pa 
$$G(x) ~=~ x - JF(x)^{-1} \cdot F(x).$$

\end{metoda}
\vspace{0.5cm}

\begin{algoritem}
~
\begin{lstlisting}
x$^{\texttt{(0)}}$
r = 0, 1,...
$~~~~$JF(x$^{\texttt{(r)}}$)$\cdot$$\Delta$x$^{\texttt{(r)}}$ = -F(x$^{\texttt{(r)}}$)
$~~~~$x$^{\texttt{(r+1)}}$ = x$^{\texttt{(r)}}$ + $\Delta$x$^{\texttt{(r)}}$
\end{lstlisting}
\end{algoritem}
\vspace{0.5cm}

% *************************************************************************************************

\pagebreak

% #################################################################################################

\section{LINEARNI PROBLEM NAJMANJŠIH \\ KVADRATOV}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Uvod}
\vspace{0.5cm}

\begin{metoda}

To je primer predoločenega sistema, kjer imamo več enačb kot neznank. V splošnem\footnote{Razen v primeru kot je $b \in \text{Im}(A)$} nima rešitve. Namesto tega iščemo $x$, ki minimizira normo ostanka $Ax-b$. Če iščemo minimum $\|Ax-b\|_2$, potem je to linearni problem najmanjših kvadratov. Ustrezen $x$ je rešitev po \textit{metodi najmanjših kvadratov}.

\end{metoda}
\vspace{0.5cm}

\begin{izrek}

Naj bo $A \in \mathbb{R}^{m \times n}$, $b \in \mathbb{R}^m$, $m \geq n$, $\text{rang}(A) = n$. Rešitev normalnega sistema
$$A^T A x ~=~ A^T b$$
je rešitev predoločenega sistema $Ax = b$ po metodi najmanjših kvadratov.

\end{izrek}
\vspace{0.5cm}

\begin{opomba}

Pravilna izpeljava:
$$A^T(Ax-b) ~=~ 0 ~~\Rightarrow~~ A^T A x = A^T b$$

\end{opomba}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Razcep Cholskega}
\vspace{0.5cm}

\begin{izrek}

Dan je sistem $Bx = c$, $B$ je simetrična pozitivno definitna\footnote{$B = B^T$, ~~~$z^T B z > 0$ ~za~ $z \neq 0$} matrika velikosti $n \times n$. Velja:
\begin{enumerate}

	\item Če je $B$ simetrična pozitivno definitna $~\Rightarrow~$ vse njene vodilne podmatrike so simetrične pozitivno definitne.
	
	\item Če je $B$ simetrična pozitivno definitna $~\Rightarrow~$ obstaja LU razcep $B = LU$, kjer je $u_{ii} > 0$ za $i = 1, \ldots, n$.
	
	\item $B$ je simetrično pozitivno definitna $~\iff~$ obstaja nesingularna spodnje trikotna matrika $U$, da je $B = U U^T$, $u_{ii} > 0$ za $i = 1, \ldots, n$.

\end{enumerate}

\end{izrek}
\vspace{0.5cm}

\begin{algoritem}
~
\begin{lstlisting}
k = 1,..., n
$~~~~$v$_{\texttt{kk}}$ = (b$_{kk}$ - $\mathlarger{\sum_{\texttt{i = 1}}^{\texttt{k - 1}}{\texttt{v}_{\texttt{ki}}}^{\texttt{2}}}$)$^{\frac{\texttt{1}}{\texttt{2}}}$
$~~~~$j = k + 1,..., n 
$~~~~~~~~$v$_{\texttt{jk}}$ = $\frac{\texttt{1}}{\texttt{v}_{\texttt{kk}}}$(b$_{\texttt{jk}}$ - $\mathlarger{\sum_{\texttt{i = 1}}^{\texttt{k-1}}}$v$_{\texttt{ji}}$v$_{\texttt{ki}}$)
\end{lstlisting}
Število operacij:
$$\sum_{k=1}^n \left( 2k + 2(n-k)k \right) ~=~ \frac{1}{3}n^3 + \mathcal{O}(n^2)$$
\end{algoritem}
\vspace{0.5cm}

\begin{metoda}

Reševanje sistema $Bx = c$, $B$ je simetrična pozitivno definitna matrika:
\begin{enumerate}
	\item $B = V V^T$
	\item reši $V y = b$
	\item reši $V^T x = y$
\end{enumerate}

\end{metoda}
\vspace{0.5cm}

\begin{metoda}

Dana je $A \in \mathbb{R}^{m \times n}$, ~$m > n$, ~$\text{rang}(A) = n$. Po metodi najmanjših kvadratov iščemo $x$. $A^T A$ je simetrična, uporabimo razcep Choleskegta:
\begin{enumerate}
	\item $B = A^T A$, ~$c = A^T b$
	\item $B = V V^T$, ~$V$ je spodnje trikotna matrika
	\item reši $V y = c$
	\item reši $V^T x = y$
\end{enumerate}

\end{metoda}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{QR razcep}
\vspace{0.5cm}

\begin{izrek}

Naj bo $A \in \mathbb{R}^{m \times n}$, ~$m \geq n$, ~$\text{rang}(A) = n$. Potem obstaja enoličen razcep $A = QR$, kjer je $Q$ matrika velikosti $m \times n$ z ortonormiranimi stolpci in $R$ zgornje trikotna matrika velikosti $n \times n$ s pozitivnimi diagonalnimi elementi.

\end{izrek}
\vspace{0.5cm}

\begin{algoritem}
~
\begin{lstlisting}
k = 1,..., n
$~~~~$q$_{\texttt{k}}$ = a$_{\texttt{k}}$
$~~~~$i = 1,..., k-1
$~~~~~~~~$r$_{\texttt{ik}}$ = ${\texttt{q}_{\texttt{i}}}^{\texttt{T}}$$\cdot$a$_{\texttt{k}}$
$~~~~~~~~$q$_{\texttt{k}}$ = q$_{\texttt{k}}$ - r$_{\texttt{ik}}$$\cdot$q$_{\texttt{i}}$ 
$~~~~$r$_{\texttt{kk}}$ = $\|\texttt{q}_{\texttt{u}}\|_{\texttt{2}}$
$~~~~$q$_{\texttt{k}}$ = $\frac{\texttt{1}}{\texttt{r}_\texttt{ku}}$q$_{\texttt{k}}$
\end{lstlisting}
Število operacij:
$$\sum_{k=1}^n \left( \sum_{i=1}^{k-1} (2m + 2m) + 2m + 1 + m \right) ~=~ 2mn^2 + \mathcal{O}(mn)$$

\end{algoritem}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Givensove rotacije}
\vspace{0.5cm}

\begin{algoritem}
~
\begin{lstlisting}
$\tilde{\texttt{Q}}$ = I$_{\texttt{m}}$ (Ce potrebujemo $\tilde{\texttt{Q}}$)
i = 1,..., n
$~~~~$k = i+1,..., m
$~~~~~~~~$r = (${\texttt{a}_{\texttt{ii}}}^{\texttt{2}}$ + ${\texttt{a}_{\texttt{ki}}}^{\texttt{2}}$)$^{\frac{\texttt{1}}{\texttt{2}}}$, c = $\frac{\texttt{a}_{\texttt{ii}}}{\texttt{r}}$, s = $\frac{\texttt{a}_{\texttt{ki}}}{\texttt{r}}$
$~~~~~~~~$A([i k], i:n) = $\begin{bmatrix}
\texttt{c} & \texttt{s} \\
\texttt{-s} & \texttt{c}
\end{bmatrix}$ A([i k], i:n)
$~~~~~~~~$b([i k]) = $\begin{bmatrix}
\texttt{c} & \texttt{s} \\
\texttt{-s} & \texttt{c}
\end{bmatrix}$ b([i k]) (Ce resujemo Ax = b po m.n.k.)
$~~~~~~~~$$\tilde{\texttt{Q}}$([i k],:) = $\begin{bmatrix}
\texttt{c} & \texttt{s} \\
\texttt{-s} & \texttt{c}
\end{bmatrix}$ $\tilde{\texttt{Q}}$([i k],:)
$\tilde{\texttt{Q}}$ = $\tilde{\texttt{Q}}^{\texttt{T}}$
\end{lstlisting}
Število operacij:
$$\sum_{i=1}^n \sum_{k=i+1}^m \left(6 + 6(n-i+1) + 6 \right) ~\approx~ \sum_{i=1}^n 6(n-i)(m-i) ~=~ 3mn^2 - n^3$$
Če potrebujemo $\tilde{Q}$, je to še dodatnih $6m^2n - 3mn^2$ operacij.

\end{algoritem}
\vspace{0.5cm}

% *************************************************************************************************

\subsection{Householderjeva zrcaljenja}

\begin{algoritem}
~
\begin{lstlisting}
$\tilde{\texttt{Q}}$ = I$_{\texttt{m}}$ (Ce potrebujemo $\tilde{\texttt{Q}}$)
i = 1,..., n (v primeru m=n le do n-1)
$~~~~$doloci w$_{\texttt{i}} \in \mathbb{R}^{\texttt{m-n+1}}$, ki prezrcali A(i:m, i) v $\pm$*$\cdot$e$_{\texttt{1}}$
$~~~~$A(i:m, i:n) = P$_{\texttt{i}}$$\cdot$A(i:m, i:n)
$~~~~$b(i:m) = P$_{\texttt{i}}$$\cdot$b(i:m)
$~~~~$$\tilde{\texttt{Q}}$(i:m,:) = P$_{\texttt{i}}$$\cdot$$\tilde{\texttt{Q}}$(i:m,:)
$\tilde{\texttt{Q}}$ = $\tilde{\texttt{Q}}^{\texttt{T}}$
\end{lstlisting}
Število operacij:
\begin{align*}
\sum_{i=1}^n (2(m-i+1) + (n-i+1)4(m-i+1) + 4(m-i+1)) ~&\approx~ \\
\approx~ \sum_{i=1}^n 4(n-i)(m-i) ~&\approx~ 2mn^2 - \frac{2}{3}n^3
\end{align*}
Če potrebujemo še $\tilde{Q}$ porabimo še dodatnih $4m^2n - 2mn^2$ operacij.

\end{algoritem}
\vspace{0.5cm}

\pagebreak

% *************************************************************************************************

\subsection{Singularni razcep (SVD)}
\vspace{0.5cm}

\begin{izrek}

Za $A \in \mathbb{R}^{m \times n}$, ~$m \geq n$, obstaja razcep $A = U \Sigma V^T$, kjer je $U$ ortogonalna matrika velikosti $m \times m$, V ortogonalna matrika velikosti $n \times n$ in $\Sigma$ matrika velikosti $m \times n$ oblike
$$\Sigma ~=~ \begin{bmatrix}
\sigma_1 & ~ & ~ \\
~ & \ddots & ~ \\
~ & ~ & \sigma_n \\
~ \\
~
\end{bmatrix},$$
kjer so $\sigma_1 \geq \sigma_2 \geq \ldots \geq \sigma_n \geq 0$ singularne vrednosti matrike $A$.

\end{izrek}
\vspace{0.5cm}

\begin{lema}

Naj bo $A \in \mathbb{R}^{m \times n}$, ~$m \geq n$, ~$\text{rang}(A) = n$. Potem je za $b \in \mathbb{R}^m$ minimum $\|Ax - b\|_2$ dosežen pri 
$$x = \sum_{i=1}^n \frac{{u_i}^T b}{\sigma_i} v_i.$$
 
\end{lema}
\vspace{0.5cm}

\begin{trditev}

Naj bo $A \in \mathbb{R}^{m \times n}$, ~$m \geq n$, ~$\text{rang}(A) = r < n$. Če je $A = U \Sigma U^T$ singularni razcep $A$, potem ima izmed vseh vektorjev $x \in \mathbb{R}^n$, ki minimizirajo $\|Ax - b\|_2$, najmanjšo normo $\|x\|_2$ vektor
$$x = \sum_{i=1}^r \frac{{u_i}^T b}{\sigma_i} v_i.$$

\end{trditev}
\vspace{0.5cm}

\begin{definicija}

Matrike $X \in \mathbb{R}^{n \times m}$ je psevdoinverz matrike $A$, če zadošča naslednjim pogojem:
\begin{enumerate}
	\item $AXA = A$
	\item $XAX = X$
	\item $(AX)^T = AX$
	\item $(XA)^T = XA$
\end{enumerate} 
Če je $A$ matrika velikosti $n \times n$, ~$\det(A) \neq 0$, potem je
$$A^+ ~=~ A^{-1}.$$ 
Če je $A$ matrika velikosti $m \times n$, ~$\text{rang}(A) = r$, ~$m \geq n$, potem je  $$A^+ ~=~ (A^T A)^{-1} A^T.$$

\end{definicija}
\vspace{0.5cm}

\begin{izrek}

Za $A \in \mathbb{R}^{m \times n}$, ~$A = U \Sigma V^T$, je
$$A^+ ~=~ V \Sigma^+ U^T,$$
kjer je
$$\Sigma^+ ~=~ \begin{bmatrix}
{\sigma_1}^{-1} & ~ & ~ & ~ & ~ & ~ \\
~ & \ddots & ~ & ~ & ~ & ~ \\
~ & ~ & {\sigma_r}^{-1} & ~ & ~ & ~ \\
~ & ~ & ~ & 0 & ~ & ~ \\
~ & ~ & ~ & ~ & \ddots & \\
~ & ~ & ~ & ~ & ~ & 0
\end{bmatrix},$$
če je $\text{rang}(A) = r$. \\

\noindent Če je $A = U \Sigma V^T$, je 
\begin{align*}
A ~&=~ \sum_{i=1}^r \sigma_1 u_i {v_i}^T \\ 
A^+ ~&=~ \sum_{i=1}^r \frac{1}{\sigma_i} v_i {u_i}^T \\
A^+ b ~&=~ \sum_{i=1}^r \frac{{u_i}^T b}{\sigma_i} v_i
\end{align*}

\end{izrek}
\vspace{0.5cm}

% *************************************************************************************************

\pagebreak

% #################################################################################################

\end{document}